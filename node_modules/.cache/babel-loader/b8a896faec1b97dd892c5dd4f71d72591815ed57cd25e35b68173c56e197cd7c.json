{"ast":null,"code":"import { marked } from 'marked';\n\n// Configure marked options\nmarked.setOptions({\n  breaks: true,\n  gfm: true\n});\n\n// Parse frontmatter from markdown content\nconst parseFrontmatter = text => {\n  const lines = text.split('\\n');\n  if (lines[0] !== '---') {\n    return {\n      data: {},\n      content: text\n    };\n  }\n  let frontmatterEnd = -1;\n  for (let i = 1; i < lines.length; i++) {\n    if (lines[i] === '---') {\n      frontmatterEnd = i;\n      break;\n    }\n  }\n  if (frontmatterEnd === -1) {\n    return {\n      data: {},\n      content: text\n    };\n  }\n  const frontmatterLines = lines.slice(1, frontmatterEnd);\n  const content = lines.slice(frontmatterEnd + 1).join('\\n');\n  const frontmatter = {};\n  frontmatterLines.forEach(line => {\n    const [key, ...valueParts] = line.split(':');\n    if (key && valueParts.length > 0) {\n      const value = valueParts.join(':').trim();\n\n      // Handle arrays (for tags, categories, etc.)\n      if (value.startsWith('[') && value.endsWith(']')) {\n        try {\n          frontmatter[key.trim()] = JSON.parse(value);\n        } catch {\n          frontmatter[key.trim()] = value.slice(1, -1).split(',').map(item => item.trim());\n        }\n      } else {\n        frontmatter[key.trim()] = value;\n      }\n    }\n  });\n  return {\n    data: frontmatter,\n    content\n  };\n};\nexport const parseMarkdown = async markdownPath => {\n  try {\n    const response = await fetch(markdownPath);\n    if (!response.ok) {\n      throw new Error(`Failed to fetch ${markdownPath}: ${response.status}`);\n    }\n    const markdownText = await response.text();\n\n    // Parse frontmatter and content\n    const {\n      data: frontmatter,\n      content\n    } = parseFrontmatter(markdownText);\n\n    // Convert markdown to HTML\n    const htmlContent = marked(content);\n    return {\n      frontmatter,\n      content: htmlContent,\n      rawContent: content\n    };\n  } catch (error) {\n    console.error('Error parsing markdown:', error);\n    return null;\n  }\n};\n\n// Get all blog files from the /blogs directory\nexport const getAllBlogFiles = async () => {\n  try {\n    // Get list of all files in the blogs directory\n    const response = await fetch('/blogs');\n    if (!response.ok) {\n      console.warn('Could not fetch blog directory listing');\n      return [];\n    }\n    const html = await response.text();\n\n    // Extract .md file names from directory listing HTML\n    const parser = new DOMParser();\n    const doc = parser.parseFromString(html, 'text/html');\n    const links = doc.querySelectorAll('a[href$=\".md\"]');\n    const blogFiles = [];\n    for (const link of links) {\n      const filename = link.getAttribute('href');\n      if (filename && filename.endsWith('.md')) {\n        try {\n          const fileResponse = await fetch(`/blogs/${filename}`);\n          if (fileResponse.ok) {\n            const content = await fileResponse.text();\n            const {\n              data: frontmatter\n            } = parseFrontmatter(content);\n            blogFiles.push({\n              filename: filename.replace('.md', ''),\n              ...frontmatter,\n              // Ensure we have a date for sorting\n              date: frontmatter.date || frontmatter.Created || new Date().toISOString().split('T')[0]\n            });\n          }\n        } catch (error) {\n          console.warn(`Could not load blog file ${filename}:`, error);\n        }\n      }\n    }\n\n    // Sort by date (newest first)\n    return blogFiles.sort((a, b) => new Date(b.date) - new Date(a.date));\n  } catch (error) {\n    console.error('Error getting blog files:', error);\n    return [];\n  }\n};","map":{"version":3,"names":["marked","setOptions","breaks","gfm","parseFrontmatter","text","lines","split","data","content","frontmatterEnd","i","length","frontmatterLines","slice","join","frontmatter","forEach","line","key","valueParts","value","trim","startsWith","endsWith","JSON","parse","map","item","parseMarkdown","markdownPath","response","fetch","ok","Error","status","markdownText","htmlContent","rawContent","error","console","getAllBlogFiles","warn","html","parser","DOMParser","doc","parseFromString","links","querySelectorAll","blogFiles","link","filename","getAttribute","fileResponse","push","replace","date","Created","Date","toISOString","sort","a","b"],"sources":["C:/Users/Soheil/Desktop/Codebase/GitHub/quant-blog/src/utils/markdownParser.js"],"sourcesContent":["import { marked } from 'marked';\r\n\r\n// Configure marked options\r\nmarked.setOptions({\r\n  breaks: true,\r\n  gfm: true\r\n});\r\n\r\n// Parse frontmatter from markdown content\r\nconst parseFrontmatter = (text) => {\r\n  const lines = text.split('\\n');\r\n  \r\n  if (lines[0] !== '---') {\r\n    return { data: {}, content: text };\r\n  }\r\n  \r\n  let frontmatterEnd = -1;\r\n  for (let i = 1; i < lines.length; i++) {\r\n    if (lines[i] === '---') {\r\n      frontmatterEnd = i;\r\n      break;\r\n    }\r\n  }\r\n  \r\n  if (frontmatterEnd === -1) {\r\n    return { data: {}, content: text };\r\n  }\r\n  \r\n  const frontmatterLines = lines.slice(1, frontmatterEnd);\r\n  const content = lines.slice(frontmatterEnd + 1).join('\\n');\r\n  \r\n  const frontmatter = {};\r\n  frontmatterLines.forEach(line => {\r\n    const [key, ...valueParts] = line.split(':');\r\n    if (key && valueParts.length > 0) {\r\n      const value = valueParts.join(':').trim();\r\n      \r\n      // Handle arrays (for tags, categories, etc.)\r\n      if (value.startsWith('[') && value.endsWith(']')) {\r\n        try {\r\n          frontmatter[key.trim()] = JSON.parse(value);\r\n        } catch {\r\n          frontmatter[key.trim()] = value.slice(1, -1).split(',').map(item => item.trim());\r\n        }\r\n      } else {\r\n        frontmatter[key.trim()] = value;\r\n      }\r\n    }\r\n  });\r\n  \r\n  return { data: frontmatter, content };\r\n};\r\n\r\nexport const parseMarkdown = async (markdownPath) => {\r\n  try {\r\n    const response = await fetch(markdownPath);\r\n    if (!response.ok) {\r\n      throw new Error(`Failed to fetch ${markdownPath}: ${response.status}`);\r\n    }\r\n    const markdownText = await response.text();\r\n    \r\n    // Parse frontmatter and content\r\n    const { data: frontmatter, content } = parseFrontmatter(markdownText);\r\n    \r\n    // Convert markdown to HTML\r\n    const htmlContent = marked(content);\r\n    \r\n    return {\r\n      frontmatter,\r\n      content: htmlContent,\r\n      rawContent: content\r\n    };\r\n  } catch (error) {\r\n    console.error('Error parsing markdown:', error);\r\n    return null;\r\n  }\r\n};\r\n\r\n// Get all blog files from the /blogs directory\r\nexport const getAllBlogFiles = async () => {\r\n  try {\r\n    // Get list of all files in the blogs directory\r\n    const response = await fetch('/blogs');\r\n    if (!response.ok) {\r\n      console.warn('Could not fetch blog directory listing');\r\n      return [];\r\n    }\r\n    \r\n    const html = await response.text();\r\n    \r\n    // Extract .md file names from directory listing HTML\r\n    const parser = new DOMParser();\r\n    const doc = parser.parseFromString(html, 'text/html');\r\n    const links = doc.querySelectorAll('a[href$=\".md\"]');\r\n    \r\n    const blogFiles = [];\r\n    \r\n    for (const link of links) {\r\n      const filename = link.getAttribute('href');\r\n      if (filename && filename.endsWith('.md')) {\r\n        try {\r\n          const fileResponse = await fetch(`/blogs/${filename}`);\r\n          if (fileResponse.ok) {\r\n            const content = await fileResponse.text();\r\n            const { data: frontmatter } = parseFrontmatter(content);\r\n            \r\n            blogFiles.push({\r\n              filename: filename.replace('.md', ''),\r\n              ...frontmatter,\r\n              // Ensure we have a date for sorting\r\n              date: frontmatter.date || frontmatter.Created || new Date().toISOString().split('T')[0]\r\n            });\r\n          }\r\n        } catch (error) {\r\n          console.warn(`Could not load blog file ${filename}:`, error);\r\n        }\r\n      }\r\n    }\r\n    \r\n    // Sort by date (newest first)\r\n    return blogFiles.sort((a, b) => new Date(b.date) - new Date(a.date));\r\n    \r\n  } catch (error) {\r\n    console.error('Error getting blog files:', error);\r\n    return [];\r\n  }\r\n}; "],"mappings":"AAAA,SAASA,MAAM,QAAQ,QAAQ;;AAE/B;AACAA,MAAM,CAACC,UAAU,CAAC;EAChBC,MAAM,EAAE,IAAI;EACZC,GAAG,EAAE;AACP,CAAC,CAAC;;AAEF;AACA,MAAMC,gBAAgB,GAAIC,IAAI,IAAK;EACjC,MAAMC,KAAK,GAAGD,IAAI,CAACE,KAAK,CAAC,IAAI,CAAC;EAE9B,IAAID,KAAK,CAAC,CAAC,CAAC,KAAK,KAAK,EAAE;IACtB,OAAO;MAAEE,IAAI,EAAE,CAAC,CAAC;MAAEC,OAAO,EAAEJ;IAAK,CAAC;EACpC;EAEA,IAAIK,cAAc,GAAG,CAAC,CAAC;EACvB,KAAK,IAAIC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGL,KAAK,CAACM,MAAM,EAAED,CAAC,EAAE,EAAE;IACrC,IAAIL,KAAK,CAACK,CAAC,CAAC,KAAK,KAAK,EAAE;MACtBD,cAAc,GAAGC,CAAC;MAClB;IACF;EACF;EAEA,IAAID,cAAc,KAAK,CAAC,CAAC,EAAE;IACzB,OAAO;MAAEF,IAAI,EAAE,CAAC,CAAC;MAAEC,OAAO,EAAEJ;IAAK,CAAC;EACpC;EAEA,MAAMQ,gBAAgB,GAAGP,KAAK,CAACQ,KAAK,CAAC,CAAC,EAAEJ,cAAc,CAAC;EACvD,MAAMD,OAAO,GAAGH,KAAK,CAACQ,KAAK,CAACJ,cAAc,GAAG,CAAC,CAAC,CAACK,IAAI,CAAC,IAAI,CAAC;EAE1D,MAAMC,WAAW,GAAG,CAAC,CAAC;EACtBH,gBAAgB,CAACI,OAAO,CAACC,IAAI,IAAI;IAC/B,MAAM,CAACC,GAAG,EAAE,GAAGC,UAAU,CAAC,GAAGF,IAAI,CAACX,KAAK,CAAC,GAAG,CAAC;IAC5C,IAAIY,GAAG,IAAIC,UAAU,CAACR,MAAM,GAAG,CAAC,EAAE;MAChC,MAAMS,KAAK,GAAGD,UAAU,CAACL,IAAI,CAAC,GAAG,CAAC,CAACO,IAAI,CAAC,CAAC;;MAEzC;MACA,IAAID,KAAK,CAACE,UAAU,CAAC,GAAG,CAAC,IAAIF,KAAK,CAACG,QAAQ,CAAC,GAAG,CAAC,EAAE;QAChD,IAAI;UACFR,WAAW,CAACG,GAAG,CAACG,IAAI,CAAC,CAAC,CAAC,GAAGG,IAAI,CAACC,KAAK,CAACL,KAAK,CAAC;QAC7C,CAAC,CAAC,MAAM;UACNL,WAAW,CAACG,GAAG,CAACG,IAAI,CAAC,CAAC,CAAC,GAAGD,KAAK,CAACP,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAACP,KAAK,CAAC,GAAG,CAAC,CAACoB,GAAG,CAACC,IAAI,IAAIA,IAAI,CAACN,IAAI,CAAC,CAAC,CAAC;QAClF;MACF,CAAC,MAAM;QACLN,WAAW,CAACG,GAAG,CAACG,IAAI,CAAC,CAAC,CAAC,GAAGD,KAAK;MACjC;IACF;EACF,CAAC,CAAC;EAEF,OAAO;IAAEb,IAAI,EAAEQ,WAAW;IAAEP;EAAQ,CAAC;AACvC,CAAC;AAED,OAAO,MAAMoB,aAAa,GAAG,MAAOC,YAAY,IAAK;EACnD,IAAI;IACF,MAAMC,QAAQ,GAAG,MAAMC,KAAK,CAACF,YAAY,CAAC;IAC1C,IAAI,CAACC,QAAQ,CAACE,EAAE,EAAE;MAChB,MAAM,IAAIC,KAAK,CAAC,mBAAmBJ,YAAY,KAAKC,QAAQ,CAACI,MAAM,EAAE,CAAC;IACxE;IACA,MAAMC,YAAY,GAAG,MAAML,QAAQ,CAAC1B,IAAI,CAAC,CAAC;;IAE1C;IACA,MAAM;MAAEG,IAAI,EAAEQ,WAAW;MAAEP;IAAQ,CAAC,GAAGL,gBAAgB,CAACgC,YAAY,CAAC;;IAErE;IACA,MAAMC,WAAW,GAAGrC,MAAM,CAACS,OAAO,CAAC;IAEnC,OAAO;MACLO,WAAW;MACXP,OAAO,EAAE4B,WAAW;MACpBC,UAAU,EAAE7B;IACd,CAAC;EACH,CAAC,CAAC,OAAO8B,KAAK,EAAE;IACdC,OAAO,CAACD,KAAK,CAAC,yBAAyB,EAAEA,KAAK,CAAC;IAC/C,OAAO,IAAI;EACb;AACF,CAAC;;AAED;AACA,OAAO,MAAME,eAAe,GAAG,MAAAA,CAAA,KAAY;EACzC,IAAI;IACF;IACA,MAAMV,QAAQ,GAAG,MAAMC,KAAK,CAAC,QAAQ,CAAC;IACtC,IAAI,CAACD,QAAQ,CAACE,EAAE,EAAE;MAChBO,OAAO,CAACE,IAAI,CAAC,wCAAwC,CAAC;MACtD,OAAO,EAAE;IACX;IAEA,MAAMC,IAAI,GAAG,MAAMZ,QAAQ,CAAC1B,IAAI,CAAC,CAAC;;IAElC;IACA,MAAMuC,MAAM,GAAG,IAAIC,SAAS,CAAC,CAAC;IAC9B,MAAMC,GAAG,GAAGF,MAAM,CAACG,eAAe,CAACJ,IAAI,EAAE,WAAW,CAAC;IACrD,MAAMK,KAAK,GAAGF,GAAG,CAACG,gBAAgB,CAAC,gBAAgB,CAAC;IAEpD,MAAMC,SAAS,GAAG,EAAE;IAEpB,KAAK,MAAMC,IAAI,IAAIH,KAAK,EAAE;MACxB,MAAMI,QAAQ,GAAGD,IAAI,CAACE,YAAY,CAAC,MAAM,CAAC;MAC1C,IAAID,QAAQ,IAAIA,QAAQ,CAAC5B,QAAQ,CAAC,KAAK,CAAC,EAAE;QACxC,IAAI;UACF,MAAM8B,YAAY,GAAG,MAAMtB,KAAK,CAAC,UAAUoB,QAAQ,EAAE,CAAC;UACtD,IAAIE,YAAY,CAACrB,EAAE,EAAE;YACnB,MAAMxB,OAAO,GAAG,MAAM6C,YAAY,CAACjD,IAAI,CAAC,CAAC;YACzC,MAAM;cAAEG,IAAI,EAAEQ;YAAY,CAAC,GAAGZ,gBAAgB,CAACK,OAAO,CAAC;YAEvDyC,SAAS,CAACK,IAAI,CAAC;cACbH,QAAQ,EAAEA,QAAQ,CAACI,OAAO,CAAC,KAAK,EAAE,EAAE,CAAC;cACrC,GAAGxC,WAAW;cACd;cACAyC,IAAI,EAAEzC,WAAW,CAACyC,IAAI,IAAIzC,WAAW,CAAC0C,OAAO,IAAI,IAAIC,IAAI,CAAC,CAAC,CAACC,WAAW,CAAC,CAAC,CAACrD,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC;YACxF,CAAC,CAAC;UACJ;QACF,CAAC,CAAC,OAAOgC,KAAK,EAAE;UACdC,OAAO,CAACE,IAAI,CAAC,4BAA4BU,QAAQ,GAAG,EAAEb,KAAK,CAAC;QAC9D;MACF;IACF;;IAEA;IACA,OAAOW,SAAS,CAACW,IAAI,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAK,IAAIJ,IAAI,CAACI,CAAC,CAACN,IAAI,CAAC,GAAG,IAAIE,IAAI,CAACG,CAAC,CAACL,IAAI,CAAC,CAAC;EAEtE,CAAC,CAAC,OAAOlB,KAAK,EAAE;IACdC,OAAO,CAACD,KAAK,CAAC,2BAA2B,EAAEA,KAAK,CAAC;IACjD,OAAO,EAAE;EACX;AACF,CAAC","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}